{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKMYDLcpGdLWuwvv4CAg+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlokeshkumar1/nlp/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thk_8jyYVn6m",
        "outputId": "2b65875c-bcbb-4a7e-cb70-7dc4d970c512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNYQ_3igV5Bf",
        "outputId": "e954da92-f5db-4fb1-c3cd-401f12efbe36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=118106e296f467bc84dd2668460af00d7907603060df55b4a85a39e873fb8f49\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.13.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install retrofit==0.1.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yxH_MtjSb0K",
        "outputId": "a48000de-003c-4827-ed13-c0cf13cbe879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: retrofit==0.1.7 in /usr/local/lib/python3.9/dist-packages (0.1.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.22.4)\n",
            "Requirement already satisfied: datatable in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.7.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (1.4.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (2.2.3)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.9/dist-packages (from retrofit==0.1.7) (0.16.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost->retrofit==0.1.7) (3.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost->retrofit==0.1.7) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost->retrofit==0.1.7) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost->retrofit==0.1.7) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->retrofit==0.1.7) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->retrofit==0.1.7) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from lightgbm->retrofit==0.1.7) (1.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from polars->retrofit==0.1.7) (4.5.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (4.39.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost->retrofit==0.1.7) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost->retrofit==0.1.7) (8.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->lightgbm->retrofit==0.1.7) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->lightgbm->retrofit==0.1.7) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from retrofitting import Retrofitter\n",
        "\n",
        "# Define the sets of tweets and labels\n",
        "Advice = [\"['Stay at home']\",\"['wash hands']\",\"['wear mask']\",\"['social distancing']\"]\n",
        "China = [\"['Wuhan']\",\"['China Coronavirus Updates']\",\"['China news']\",\"['other tweets related to China']\"]\n",
        "Mask = [\"['Mask shortage']\",\"['wear mask']\",\"['mask types']\",\"['N50']\",\"['N95']\",\"['3M8210']\",\"['3M9001']\",\"['3M9322']\",\"['3M9501']\"]\n",
        "News = [\"['Coronavirus updates']\",\"['news']\",\"['rules']\"]\n",
        "Transportation = [\"['Flights']\",\"['traffic']\",\"['traveling']\"]\n",
        "USA = [\"['U.S. Coronavirus Updates']\",\"['COVID19']\",\"['U.S. news']\",\"['United States']\",\"['US']\",\"['USA']\"]\n",
        "Vaccine = [\"['Vaccine news']\",\"['vaccine progress']\",\"['vaccine injection']\"]\n",
        "tweets = Advice + China + Mask + News + Transportation + USA + Vaccine\n",
        "labels = [\"Vaccine\",\"USA\",\"Transportation\",\"News\",\"Mask\",\"China\",\"Advice\"]\n",
        "\n",
        "# Read CSV files and merge them into a single dataframe\n",
        "RESULTS_DIR = 'drive/MyDrive'\n",
        "df1 = pd.read_csv(RESULTS_DIR + '/D11.csv', encoding='latin1', engine='python')\n",
        "df2 = pd.read_csv(RESULTS_DIR + '/D2.csv', encoding='latin1', engine='python')\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Extract string attributes from hashtag values\n",
        "df['hashtags'] = df['hashtags'].str.findall(r\"'(.*?)'\").apply(lambda x: [item for item in x if item])\n",
        "\n",
        "# Filter tweets by hashtags\n",
        "df['tweet_type'] = df['hashtags'].apply(lambda x: list(set(x).intersection(set(tweets))))\n",
        "\n",
        "# Load the pre-trained S-BERT model\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# Embed the tweets and labels using the S-BERT model\n",
        "tweet_embeddings = model.encode(df['text'])\n",
        "label_embeddings = model.encode(labels)\n",
        "\n",
        "# Load the knowledge graph (ConceptNet)\n",
        "knowledge_graph = pd.read_csv('conceptnet.csv')\n",
        "\n",
        "# Retrofit the knowledge graph embeddings\n",
        "retrofitter = Retrofitter(model=model, graph=knowledge_graph, dim=768)\n",
        "retrofitter.fit()\n",
        "\n",
        "# Project the tweet embeddings and label embeddings onto the knowledge graph embedding space\n",
        "projected_tweet_embeddings = torch.matmul(tweet_embeddings, retrofitter.P)\n",
        "projected_label_embeddings = torch.matmul(label_embeddings, retrofitter.P)\n",
        "\n",
        "# Classify the tweets using cosine similarity\n",
        "for i, tweet_embedding in enumerate(projected_tweet_embeddings):\n",
        "    max_sim = 0\n",
        "    for j, label_embedding in enumerate(projected_label_embeddings):\n",
        "        sim = util.cos_sim(tweet_embedding, label_embedding)\n",
        "        if sim > max_sim:\n",
        "            max_sim = sim\n",
        "            tweet_label = labels[j]\n",
        "    df.loc[i, 'tweet_label'] = tweet_label\n",
        "\n",
        "# Print the classified tweets\n",
        "print(df[['text', 'tweet_label']])"
      ],
      "metadata": {
        "id": "RyE7_r0buB3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}